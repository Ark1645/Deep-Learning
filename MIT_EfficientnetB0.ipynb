{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1z0LAqUpr3_upWFkXEzJ082UQOyZtIgSf",
      "authorship_tag": "ABX9TyP2q9auQELS5IRo3su5rAIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ark1645/Deep-Learning/blob/main/MIT_EfficientnetB0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ELqIfM3dBEow"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pylab as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/MIT Indoorscene/indoorCVPR_09/Images'\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 64\n",
        "#nb_epochs = 10"
      ],
      "metadata": {
        "id": "63nYIUGMBFQW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prefucn(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=1 - 0.2, upper=1 + 0.2)\n",
        "    image = tf.image.random_saturation(image, lower=1 - 0.2, upper=1 + 0.2)\n",
        "    image = tf.image.random_hue(image, max_delta=0.2)\n",
        "    return image"
      ],
      "metadata": {
        "id": "AFpp8zyoBI08"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=prefucn,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1\n",
        "    )"
      ],
      "metadata": {
        "id": "Atr-1SpFBKP9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    root,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MsEvhFEBKxp",
        "outputId": "54e69e1f-f13a-4c35-a7e1-689f73603bff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14089 images belonging to 69 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    root,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbKSLZeyBMPx",
        "outputId": "9c71a5e5-70ac-462c-b46c-7b0ae94eccda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1532 images belonging to 69 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices\n",
        "print(class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTk7qmQuBN1h",
        "outputId": "6982e33d-aa1e-4705-f8ee-7f05c20f2fcd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'airport_inside': 0, 'artstudio': 1, 'assets': 2, 'auditorium': 3, 'bakery': 4, 'bar': 5, 'bathroom': 6, 'bedroom': 7, 'bookstore': 8, 'bowling': 9, 'buffet': 10, 'casino': 11, 'children_room': 12, 'church_inside': 13, 'classroom': 14, 'cloister': 15, 'closet': 16, 'clothingstore': 17, 'computerroom': 18, 'concert_hall': 19, 'corridor': 20, 'deli': 21, 'dentaloffice': 22, 'dining_room': 23, 'elevator': 24, 'fastfood_restaurant': 25, 'florist': 26, 'gameroom': 27, 'garage': 28, 'greenhouse': 29, 'grocerystore': 30, 'gym': 31, 'hairsalon': 32, 'hospitalroom': 33, 'inside_bus': 34, 'inside_subway': 35, 'jewelleryshop': 36, 'kindergarden': 37, 'kitchen': 38, 'laboratorywet': 39, 'laundromat': 40, 'library': 41, 'livingroom': 42, 'lobby': 43, 'locker_room': 44, 'mall': 45, 'meeting_room': 46, 'movietheater': 47, 'museum': 48, 'nursery': 49, 'office': 50, 'operating_room': 51, 'pantry': 52, 'poolinside': 53, 'prisoncell': 54, 'restaurant': 55, 'restaurant_kitchen': 56, 'shoeshop': 57, 'stairscase': 58, 'studiomusic': 59, 'subway': 60, 'toystore': 61, 'trainstation': 62, 'tv_studio': 63, 'variables': 64, 'videostore': 65, 'waitingroom': 66, 'warehouse': 67, 'winecellar': 68}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base =  mobilenet_v2.MobileNetV2(include_top = False, weights='imagenet',input_shape = (224,224,3))"
      ],
      "metadata": {
        "id": "c9eJdZjMBQpx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "i9yK4PPjBR--"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwRGB_neCITM",
        "outputId": "3c2ad101-62de-4f8f-b1ff-a3d9ab58f356"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n"
      ],
      "metadata": {
        "id": "K9p3fPo3CKrm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the desired EfficientNet variant (e.g., EfficientNetB0, EfficientNetB2)\n",
        "efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze pre-trained layers (optional)\n",
        "#for layer in efficientnet_base.layers[:-n]:  # Freeze the first n layers (experiment with n)\n",
        " #   layer.trainable = False\n"
      ],
      "metadata": {
        "id": "n2z88K-DCfhT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(efficientnet_base)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(Dense(69, activation='softmax'))"
      ],
      "metadata": {
        "id": "7ACOdXpZBU_8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb6YBbVYBVm6",
        "outputId": "3b491dd2-856a-4431-b9b6-34cf67e9bf6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional  (None, 7, 7, 1280)        4049571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 1280)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 69)                88389     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4137960 (15.79 MB)\n",
            "Trainable params: 4095937 (15.62 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adam(learning_rate=6e-5 ), 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "qSczoJvFBXFs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model.h5', save_weights_only=True, save_freq=1)"
      ],
      "metadata": {
        "id": "q4dFN_cPBcPJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = 3,\n",
        "    callbacks=[checkpoint]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttINgRH7Bd7J",
        "outputId": "95c994d6-df33-44f6-dc51-fa97e1e0bed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "220/220 [==============================] - 5150s 23s/step - loss: 3.6276 - accuracy: 0.1835 - val_loss: 2.7459 - val_accuracy: 0.3519\n",
            "Epoch 2/3\n",
            "220/220 [==============================] - 5172s 23s/step - loss: 2.2824 - accuracy: 0.4560 - val_loss: 1.7453 - val_accuracy: 0.5516\n",
            "Epoch 3/3\n",
            "220/220 [==============================] - 5125s 23s/step - loss: 1.5878 - accuracy: 0.5919 - val_loss: 1.2841 - val_accuracy: 0.6583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print('Validation loss:', loss)\n",
        "print('Validation accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "PuRdP-kRBgBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "16dc6b0c-263f-444e-902a-044442629ac8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c98c535021e0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "# Plot loss curves\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Predict labels\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# True labels\n",
        "y_true = validation_generator.classes\n",
        "\n",
        "# F1 Score, Precision, Recall\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# # Confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "# print(\"Confusion Matrix:\")\n",
        "# print(conf_matrix)\n",
        "\n",
        "# # Classification report\n",
        "# class_labels = list(validation_generator.class_indices.keys())\n",
        "# report = classification_report(y_true, y_pred, target_names=class_labels)\n",
        "# print(\"Classification Report:\")\n",
        "# print(report)\n"
      ],
      "metadata": {
        "id": "CIGWXQh8ct2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get validation data (images and labels)\n",
        "validation_data = (X_val, y_val)  # Replace with your validation data\n",
        "\n",
        "# Make predictions on validation data\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "recall = recall_score(y_val.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\n",
        "precision = precision_score(y_val.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\n",
        "f1 = f1_score(y_val.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\n",
        "\n",
        "print(f'Recall: {recall:.4f}, Precision: {precision:.4f}, F1-Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "2n9JLcad9nZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract loss and accuracy data from history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot loss curves\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rq_eG1pI98iy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}